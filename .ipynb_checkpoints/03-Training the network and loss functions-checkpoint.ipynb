{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3178, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10)\n",
    "                     )\n",
    "\n",
    "# Defining the Cross Entropy Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Calculating the Logits\n",
    "logits = model(images)\n",
    "\n",
    "# Calculating the Loss\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLLLoss with log softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2990, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd- Working with Gradients\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, autograd, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad=True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "---\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()`\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`\n",
    "\n",
    "The gradients are computed with respect to some variable z with `z.backward()`. This does a backward pass through the operations that created z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2477,  1.0298],\n",
      "        [-1.9966,  0.6522]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0614, 1.0604],\n",
      "        [3.9863, 0.4254]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x0000023A92A76AF0>\n"
     ]
    }
   ],
   "source": [
    "# operation done for gradient\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3834, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# since we haven't still invoked the backwards method, the gradients are not yet calculated, therefore are empty\n",
    "print(x.grad)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While calculating mathematically, the gradient of *z* with respect to *x* is:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1239,  0.5149],\n",
      "        [-0.9983,  0.3261]])\n",
      "tensor([[ 0.1239,  0.5149],\n",
      "        [-0.9983,  0.3261]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# computing the gradient\n",
    "z.backward()\n",
    "# this computes gradient of z w.r.t. x\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Loss and Autograd Together\n",
    "\n",
    "The gradients from the loss is used for updating the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3214, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1)\n",
    "                     )\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0041, -0.0041, -0.0041,  ..., -0.0041, -0.0041, -0.0041],\n",
      "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
      "        [ 0.0046,  0.0046,  0.0046,  ...,  0.0046,  0.0046,  0.0046],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general steps in  pytorch for training:\n",
    "\n",
    "- Make a forward pass through the network\n",
    "- Use the network output to calculate the loss\n",
    "- Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "- Take a step with the optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights: \n",
      " Parameter containing:\n",
      "tensor([[-0.0197, -0.0323,  0.0153,  ...,  0.0176,  0.0260,  0.0187],\n",
      "        [-0.0271,  0.0114, -0.0140,  ..., -0.0346,  0.0087, -0.0087],\n",
      "        [-0.0254,  0.0135, -0.0055,  ...,  0.0351,  0.0182,  0.0037],\n",
      "        ...,\n",
      "        [ 0.0044, -0.0280, -0.0007,  ...,  0.0119,  0.0131, -0.0178],\n",
      "        [ 0.0098, -0.0295, -0.0099,  ..., -0.0319,  0.0003,  0.0247],\n",
      "        [-0.0269,  0.0033,  0.0271,  ..., -0.0355, -0.0090,  0.0197]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Gradient: \n",
      " tensor([[-0.0041, -0.0041, -0.0041,  ..., -0.0041, -0.0041, -0.0041],\n",
      "        [ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
      "        [ 0.0025,  0.0025,  0.0025,  ...,  0.0025,  0.0025,  0.0025],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [ 0.0011,  0.0011,  0.0011,  ...,  0.0011,  0.0011,  0.0011]])\n"
     ]
    }
   ],
   "source": [
    "print(\"initial weights: \\n\", model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Pytorch by default accumulates the gradients by summing them up\n",
    "# therefore we need to clear all those gradients first\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass\n",
    "op = model(images)\n",
    "loss = criterion(op, labels)\n",
    "loss.backward()\n",
    "print('\\nGradient: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights: \n",
      " Parameter containing:\n",
      "tensor([[-0.0197, -0.0323,  0.0153,  ...,  0.0176,  0.0261,  0.0187],\n",
      "        [-0.0271,  0.0114, -0.0140,  ..., -0.0346,  0.0086, -0.0087],\n",
      "        [-0.0254,  0.0135, -0.0055,  ...,  0.0351,  0.0181,  0.0037],\n",
      "        ...,\n",
      "        [ 0.0044, -0.0280, -0.0007,  ...,  0.0119,  0.0131, -0.0178],\n",
      "        [ 0.0098, -0.0295, -0.0099,  ..., -0.0319,  0.0003,  0.0247],\n",
      "        [-0.0269,  0.0032,  0.0271,  ..., -0.0355, -0.0090,  0.0197]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Updating the weights\n",
    "optimizer.step()\n",
    "print('Updated weights: \\n', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8673890319460236\n",
      "Training loss: 0.827770696075232\n",
      "Training loss: 0.5283979232123157\n",
      "Training loss: 0.4309013792033643\n",
      "Training loss: 0.38518756535897125\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        op = model(images)\n",
    "        loss = criterion(op, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
