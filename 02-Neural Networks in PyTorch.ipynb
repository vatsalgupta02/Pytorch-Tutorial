{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import helper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Normalixing the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                               ])\n",
    "\n",
    "# Downloading the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "detaiter = iter(trainloader)\n",
    "images, labels = detaiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2ecc670db80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "# Flattening the images\n",
    "img = images.view(images.shape[0], -1)\n",
    "\n",
    "# Initializing the network parameters\n",
    "n_input = img.shape[-1]\n",
    "n_hidden = 256\n",
    "n_output = 10\n",
    "\n",
    "# Initializing the weights\n",
    "W1 = torch.randn((n_input, n_hidden))\n",
    "W2 = torch.randn((n_hidden, n_output))\n",
    "\n",
    "# Initializing the Biases\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))\n",
    "\n",
    "h = sigmoid(torch.mm(img, W1) + B1)\n",
    "out = torch.mm(h, W2) + B2\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementing the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1,1)\n",
    "\n",
    "prob = softmax(out)\n",
    "\n",
    "print(prob.shape)\n",
    "print(torch.sum(prob, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "#         layers\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "#         Activations\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "#     feed-forward network\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using torch.nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "#         layers\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "#         No need for defining activations separately\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.hidden(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Network at 0x2ecc8e12f10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultiNetwork at 0x2ecc9259f70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiNetwork():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h1 = nn.Linear(784, 128)\n",
    "        self.h2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.relu(self.h2(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = MultiNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0077, -0.0184,  0.0074,  ...,  0.0339,  0.0134, -0.0223],\n",
      "        [-0.0317,  0.0030,  0.0131,  ..., -0.0340,  0.0013,  0.0010],\n",
      "        [-0.0225, -0.0131,  0.0140,  ...,  0.0084, -0.0352,  0.0013],\n",
      "        ...,\n",
      "        [ 0.0180,  0.0279,  0.0241,  ..., -0.0120,  0.0193, -0.0282],\n",
      "        [-0.0259,  0.0141, -0.0159,  ..., -0.0215,  0.0193,  0.0222],\n",
      "        [ 0.0151, -0.0058,  0.0117,  ..., -0.0343,  0.0273, -0.0004]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0295, -0.0165,  0.0026, -0.0333, -0.0123,  0.0266, -0.0348,  0.0346,\n",
      "         0.0322,  0.0300, -0.0087, -0.0336,  0.0067, -0.0295,  0.0209, -0.0262,\n",
      "        -0.0188, -0.0092, -0.0199, -0.0047, -0.0022, -0.0263, -0.0029,  0.0231,\n",
      "         0.0210,  0.0207,  0.0046,  0.0203,  0.0127, -0.0061,  0.0296,  0.0010,\n",
      "         0.0181,  0.0325,  0.0061,  0.0331, -0.0025, -0.0126,  0.0018, -0.0228,\n",
      "         0.0113, -0.0329,  0.0274,  0.0083,  0.0239, -0.0155, -0.0297, -0.0062,\n",
      "        -0.0064,  0.0212,  0.0334,  0.0172,  0.0133,  0.0284, -0.0077,  0.0290,\n",
      "        -0.0039,  0.0119, -0.0300,  0.0160,  0.0102, -0.0050,  0.0305,  0.0089,\n",
      "         0.0165,  0.0048, -0.0038,  0.0181,  0.0310,  0.0330, -0.0266, -0.0355,\n",
      "         0.0070,  0.0171,  0.0019,  0.0059, -0.0187, -0.0224,  0.0186,  0.0101,\n",
      "        -0.0137,  0.0300, -0.0192, -0.0225,  0.0144, -0.0087, -0.0185, -0.0152,\n",
      "        -0.0055,  0.0119,  0.0269, -0.0343, -0.0096, -0.0314,  0.0032, -0.0216,\n",
      "         0.0317,  0.0325,  0.0115,  0.0289, -0.0064, -0.0208,  0.0296, -0.0189,\n",
      "         0.0030, -0.0018,  0.0189, -0.0350, -0.0197,  0.0307,  0.0224, -0.0064,\n",
      "        -0.0340,  0.0172, -0.0198, -0.0323,  0.0095, -0.0139,  0.0236,  0.0205,\n",
      "         0.0281, -0.0297, -0.0255, -0.0248, -0.0077, -0.0217, -0.0083, -0.0096],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print weights and biases\n",
    "print(model.h1.weight)\n",
    "print(model.h1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting biases to all zeros\n",
    "model.h1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0019,  0.0123,  0.0213,  ..., -0.0051, -0.0023,  0.0083],\n",
       "        [ 0.0117, -0.0119, -0.0055,  ...,  0.0033,  0.0179, -0.0029],\n",
       "        [-0.0014, -0.0147, -0.0021,  ..., -0.0056, -0.0263,  0.0018],\n",
       "        ...,\n",
       "        [-0.0020, -0.0005, -0.0061,  ..., -0.0031, -0.0090,  0.0056],\n",
       "        [-0.0170, -0.0139,  0.0013,  ..., -0.0052,  0.0057, -0.0279],\n",
       "        [-0.0226,  0.0135, -0.0109,  ..., -0.0015, -0.0030, -0.0140]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting weights with normal distribution distribution having std dev=0.01\n",
    "model.h1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward pass with an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1089, 0.0970, 0.1031, 0.0975, 0.1059, 0.0962, 0.0944, 0.0868, 0.1009,\n",
       "         0.1094]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "images.resize_(64, 1, 784)\n",
    "\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using nn.Sequential() for building sequential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# building a feed forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_size[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_size[0], hidden_size[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_size[1], output_size),\n",
    "                      nn.Softmax(dim=1)\n",
    "                     )\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0231, -0.0056, -0.0340,  ..., -0.0065, -0.0165, -0.0207],\n",
       "        [ 0.0017, -0.0262, -0.0172,  ..., -0.0327,  0.0113,  0.0185],\n",
       "        [-0.0214,  0.0243, -0.0074,  ..., -0.0063, -0.0090,  0.0182],\n",
       "        ...,\n",
       "        [ 0.0198,  0.0243,  0.0246,  ...,  0.0267, -0.0134,  0.0128],\n",
       "        [-0.0016,  0.0147,  0.0162,  ..., -0.0159, -0.0132,  0.0175],\n",
       "        [-0.0106, -0.0130,  0.0343,  ..., -0.0052, -0.0342, -0.0124]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Ordered Dictionary for creating the sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                    ('fc1', nn.Linear(input_size, hidden_size[0])),\n",
    "                    ('relu1', nn.ReLU()),\n",
    "                    ('fc2', nn.Linear(hidden_size[0], hidden_size[1])),\n",
    "                    ('relu2', nn.ReLU()),\n",
    "                    ('output', nn.Linear(hidden_size[1], output_size)),\n",
    "                    ('softmax', nn.Softmax(dim=1))\n",
    "]))\n",
    "\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
