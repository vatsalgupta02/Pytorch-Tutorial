{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3060, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10)\n",
    "                     )\n",
    "\n",
    "# Defining the Cross Entropy Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Calculating the Logits\n",
    "logits = model(images)\n",
    "\n",
    "# Calculating the Loss\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLLLoss with log softmax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2991, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd- Working with Gradients\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, autograd, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad=True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
    "\n",
    "---\n",
    "\n",
    "You can turn off gradients for a block of code with the `torch.no_grad()`\n",
    "\n",
    "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`\n",
    "\n",
    "The gradients are computed with respect to some variable z with `z.backward()`. This does a backward pass through the operations that created z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1798, -0.6411],\n",
      "        [ 0.2666, -1.4253]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3919, 0.4109],\n",
      "        [0.0710, 2.0314]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x00000257C5494E80>\n"
     ]
    }
   ],
   "source": [
    "# operation done for gradient\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9763, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# since we haven't still invoked the backwards method, the gradients are not yet calculated, therefore are empty\n",
    "print(x.grad)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While calculating mathematically, the gradient of *z* with respect to *x* is:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5899, -0.3205],\n",
      "        [ 0.1333, -0.7126]])\n",
      "tensor([[-0.5899, -0.3205],\n",
      "        [ 0.1333, -0.7126]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# computing the gradient\n",
    "z.backward()\n",
    "# this computes gradient of z w.r.t. x\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Loss and Autograd Together\n",
    "\n",
    "The gradients from the loss is used for updating the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2900, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1)\n",
    "                     )\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 1.6325e-03,  1.6325e-03,  1.6325e-03,  ...,  1.6325e-03,\n",
      "          1.6325e-03,  1.6325e-03],\n",
      "        [-6.5324e-05, -6.5324e-05, -6.5324e-05,  ..., -6.5324e-05,\n",
      "         -6.5324e-05, -6.5324e-05],\n",
      "        [-2.2056e-04, -2.2056e-04, -2.2056e-04,  ..., -2.2056e-04,\n",
      "         -2.2056e-04, -2.2056e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4443e-04,  2.4443e-04,  2.4443e-04,  ...,  2.4443e-04,\n",
      "          2.4443e-04,  2.4443e-04],\n",
      "        [ 1.2610e-03,  1.2610e-03,  1.2610e-03,  ...,  1.2610e-03,\n",
      "          1.2610e-03,  1.2610e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general steps in  pytorch for training:\n",
    "\n",
    "- Make a forward pass through the network\n",
    "- Use the network output to calculate the loss\n",
    "- Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "- Take a step with the optimizer to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights: \n",
      " Parameter containing:\n",
      "tensor([[-0.0290, -0.0023,  0.0269,  ...,  0.0183,  0.0299, -0.0282],\n",
      "        [-0.0045, -0.0276, -0.0174,  ..., -0.0256,  0.0131,  0.0210],\n",
      "        [-0.0194,  0.0220, -0.0201,  ..., -0.0066, -0.0354,  0.0093],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0083,  0.0199,  ..., -0.0333,  0.0296, -0.0076],\n",
      "        [-0.0023, -0.0268,  0.0169,  ..., -0.0058,  0.0144,  0.0014],\n",
      "        [-0.0285, -0.0091, -0.0101,  ..., -0.0348,  0.0015, -0.0008]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Gradient: \n",
      " tensor([[ 1.4998e-04,  1.4998e-04,  1.4998e-04,  ...,  1.4998e-04,\n",
      "          1.4998e-04,  1.4998e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9934e-03,  1.9934e-03,  1.9934e-03,  ...,  1.9934e-03,\n",
      "          1.9934e-03,  1.9934e-03],\n",
      "        ...,\n",
      "        [-4.7124e-05, -4.7124e-05, -4.7124e-05,  ..., -4.7124e-05,\n",
      "         -4.7124e-05, -4.7124e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 3.1784e-03,  3.1784e-03,  3.1784e-03,  ...,  3.1784e-03,\n",
      "          3.1784e-03,  3.1784e-03]])\n"
     ]
    }
   ],
   "source": [
    "print(\"initial weights: \\n\", model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Pytorch by default accumulates the gradients by summing them up\n",
    "# therefore we need to clear all those gradients first\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass\n",
    "op = model(images)\n",
    "loss = criterion(op, labels)\n",
    "loss.backward()\n",
    "print('\\nGradient: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights: \n",
      " Parameter containing:\n",
      "tensor([[-0.0290, -0.0023,  0.0269,  ...,  0.0183,  0.0299, -0.0282],\n",
      "        [-0.0045, -0.0276, -0.0174,  ..., -0.0256,  0.0131,  0.0210],\n",
      "        [-0.0194,  0.0220, -0.0201,  ..., -0.0066, -0.0354,  0.0093],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0083,  0.0199,  ..., -0.0333,  0.0296, -0.0076],\n",
      "        [-0.0023, -0.0268,  0.0169,  ..., -0.0058,  0.0144,  0.0014],\n",
      "        [-0.0286, -0.0091, -0.0101,  ..., -0.0349,  0.0015, -0.0009]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Updating the weights\n",
    "optimizer.step()\n",
    "print('Updated weights: \\n', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.862309157340003\n",
      "Training loss: 0.8073824465211267\n",
      "Training loss: 0.5174174958518319\n",
      "Training loss: 0.427651985971404\n",
      "Training loss: 0.38431325205353534\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        op = model(images)\n",
    "        loss = criterion(op, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0008, 0.0090, 0.0022, 0.3085, 0.0029, 0.2001, 0.0007, 0.0021, 0.4534,\n",
       "         0.0204]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "\n",
    "plt.imshow(img.view(28,28), cmap='gray')\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
